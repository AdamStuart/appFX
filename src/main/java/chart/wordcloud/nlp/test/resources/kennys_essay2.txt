
This paper looks at various neural network designs, with some emphasis on back-error propagation algorithm and analyzes to what degree each model is capable of emulating intelligence.

Before trying to design an artificial neural network it is important to understand some basic principles about how biological neurons function. It should be noted that this is a very brief overview of biological neural networks. The neuron is a core component of the brain functioning primarily to transmit data from one cell to another. There are many variations of neurons each ranging in function and structure depending on what their purpose is. Neurons generate and electric signal, also known as an action potential, of which propagates through the cell, along the axon to other connecting neuron cells. The propagation of the signals is made possible by the flow of ions through the cell membrane. Some of the important ions include sodium (Na+), potassium (K+), chloride (Cl-), and calcium (Ca2+). As well as the electric potential across the cell membrane, there are other factors also affecting the activity of a neuron including; various types of neurons, and various types of neurotransmitters each with a different function and purpose. Some neurons excite their target neurons using such transmitters as acetylcholine, while others inhibit their target neurons. Some inhibitory neurotransmitters include GABA and glycine. There are also groups of neurons called modulatory neurons that are invoked with more complexity. Such neurotransmitters are dopamine, acetylcholine, serotonin and others. 1 (Wikipdedia)

For example, dopamine has the function of controlling the flow of information from other areas of the brain to the frontal lobe. Dopamine is also commonly known for its association with feelings and emotions. 2(Wikipedia) The above image gives a simple representation of a typical neuron cell. Labeled are a few of its functional components.
Just to give an idea of approximately how many neurons and synapses are present in biological organisms refer to the table below. Even if a perfect model of a human brain is developed, one can see that simply due to the extremely large number of neurons and synapses that perform meaningful computations would be near impossible.
It is also interesting to observe that the number of synapses present in a human child is many times larger, approximately 20-30 times, than that of an adult. This happens as organisms learn, unused and unimportant synapses die.
An artificial neural network is a computational model based on a biological neural network, commonly referred to as a neural network or NN. It is an interconnected webbing of artificial neurons used to model complex relationships between inputs and outputs or to find patterns in data. There are many successful models already in existence. Before analyzing current learning algorithms, let’s first look at ways to structure a neural network. The Below models represent the two most common ways to represent neuron connections in a neural network; A layered neural network, meaning that neurons in one layer are connected only to neurons in the next layer. I.e. neurons in layeri are connected to layeri+1. In the Reciprocal model, neurons do not have any particular rule governing which neuron that they are connected to. This means that it is possible for a neuron in one layer to make connections to a neuron in the same layer, a previous layer, the next layer, or even to itself. While these models are harder to apply current learning algorithm models to, they offer much more flexibility and computational ability of the neural networks.
After the designing the layout of the neural network, you must next define how each of the nodes, or neurons, will function in the system. Developing an artificial neuron entails deciding how the neurons manage incoming signals, fire, and respond to other stimuli, all directly depending on the model. A common attribute of artificial neurons includes an activation function. There are two main types, they can be seen in the below two graphs:
The first graph represents an “all-or-none” type of function meaning that if the incoming signals do not sum up to a specific point the neuron will not fire, i.e. produce an output signal. A neuron containing an activation function as represented in the right graph, will always produce an output regardless of the sum of the input signals.
The below graph displays a simple activation function, where Ni = neuron value neuroni, and Wi = weighti, and a = the output value of the neuron.
There are a few main categories of which neural network learning algorithms are broken into. Some primary methods include: supervised learning, unsupervised learning, reinforced learning, as well as many other models such as genetic algorithms. The below diagrams show a visual representation of three commonly used models. Of the three, supervised learning and reinforced learning being the more frequently used.
Algorithms such as supervised learning are commonly used in solving problems like teaching a neural network a specific function. For example, if you input 1+1, the correct output is 2. Thus, in supervised learning the teacher signal would be 2 and would repeat until the learning algorithm output the desired value of 2.
In reinforced learning, the neural network has a problem to solve, for example, learning to walk, or playing tic-tac-toe. The environmental state would first be input into the neural network, as well as being processed to determine whether to punish or reward the neural network based on the state of the environment. Then, based on the new input and how the neural network was rewarded or punished it would produce another output, thus again changing the state of the environment. This process is continuously repeated until a desired stage is reached or is manually stopped.
Variable Definition: Input Layer i ; Center Layer j ; connection weight between j and i
is represented by ￼ ; Output Layer value y ; and Teacher Signal t . Back-error propagation algorithm: 3(Wikipedia)
1. Input the training data into the neural network.
2. Calculate the error between the actual output and the desired output.
3. For each neuron, calculate what the output should have been, and a scaling factor to correct the value to match the desired output. This is commonly referred to as the local error.
4. Adjust each the weights of each neuron to lower the local error.
5. Assign “blame” for the local error to neurons in the previous layer, giving greater responsibility to neurons connected by stronger weights.
6. Repeat from step 3 on the neurons at the previous level using each one’s “blame” as its error.
Advanced Neural Network Design 7
The below series of graphs give a visual representation of back-error propagation algorithm.
η = Learning Coefficient, δ = Error, y = Output, fi (e) = Bias Function, w = connection weight, i = Input Data
First, input the data and calculate the middle layer’s neuron values.
Calculate the output layer’s neuron values.
Calculate the difference between the actual output and the expected output.
￼￼￼Advanced Neural Network Design 8
￼Back-propagate, calculating the error of each of the connection weights in the center and input layers.
Next, forward propagate, adjusting each of the connection weights based on their errors.
The following tables summarize the results of the training of the Logical AND function under various conditions. For this simple experiment a two input Logical AND gate was taught. Its truth table can be seen below.
Why is it important to think about other designs considering there are already many working models? It is simple. In many neural network learning algorithms, for example, back-error propagation is more or less just trying to minimize error by adjusting matrices values. This is not how biological neurons function. Also, biological neurons more or less function as individual entities and not necessarily as coupled as they are in many artificial neural network models. So looking at biological functionality more before designing an artificial neural network will provide more insight on designing a better learning algorithm. In fact, instead of programming a learning algorithm, perhaps only programming a neuron that emulates a biological neuron, then putting the neurons together will be enough to recreate artificial intelligence, and then again maybe it will not. Other food for thought is that there are many features present in a biological neural network that may not be necessary to create an equally functional artificial neuron. For example, neuron shape in biology plays an enormous role in neuron function. However, in an artificial neural network it may be possible to ignore this property, as long as other functionality is not hindered.
Below are some diagrams that demonstrate types of thought processes. In simple feed-forward networks where data only travels in one direction, an internal cyclic thought cycle is not possible. This means that if input from the environment is stopped at any point, the neural network can not longer “think,” i.e. produce output. This is not the case in organisms, such as human beings, where even if all input is cut off, we are still capable of maintaining a thought cycle. For example if you shut your eyes and go into a quiet neutral room, you can still count and think of other complex logical problems.
The above diagrams demonstrate a one way thought process vs. a cyclic-thought cycle. Closely observe the below diagrams and note that as the number of layers that each layer is connected to increases, the ability to maintain an internal cyclic thought also increases. These sort of neural networks are referred to as recurrent neural networks.
The purpose of this document is to analyze many aspects and factors to consider when designing an artificial neural network. While there are many models available, each has its limitations. In a world where technology is growing fast, so is the desire to have software and robots capable of high level thought. Nevertheless, in the world of AI the biggest challenge lies more in the limitations of the hardware than in our ability to develop hardy learning algorithms.
